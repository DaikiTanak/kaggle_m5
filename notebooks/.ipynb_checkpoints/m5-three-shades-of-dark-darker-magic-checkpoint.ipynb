{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このNotebookはYakovlevの [M5 - Three shades of Dark: Darker magic](https://www.kaggle.com/kyakovlev/m5-three-shades-of-dark-darker-magic) を研究するために作ったものをShareしています。\n",
    "\n",
    "Thank Yakovlev for sharing very much.\n",
    "\n",
    "次のNotebookにも依存していることに注意しましょう。<br>\n",
    "[【日本語】M5 - Simple FE](https://www.kaggle.com/ejunichi/m5-simple-fe)<br>\n",
    "[M5 - Custom features](https://www.kaggle.com/kyakovlev/m5-custom-features)<br>\n",
    "[M5 - Lags features](https://www.kaggle.com/kyakovlev/m5-lags-features)　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### ヘルパー\n",
    "#################################################################################\n",
    "## シード生成\n",
    "# ：すべてのプロセスを確定的にするためのシード     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "## マルチプロセス実行\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### store IDによってデータをロードするヘルパー\n",
    "#################################################################################\n",
    "# データ読込\n",
    "def get_data_by_store(store):\n",
    "    \n",
    "    # 基本特徴量を読んで連絡する\n",
    "    # BASE,PRICE,CALENDARは「【日本語】M5 - Simple FE」を参照\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # 関連する店舗のみを残す\n",
    "    df = df[df['store_id']==store]\n",
    "\n",
    "    # メモリの制限があるため、LAGとエンコード特徴量を個別に読み取り、\n",
    "    # 不要なアイテムを削除する必要があります。 \n",
    "    # 特徴量グリッドが整列されるため、必要な行のみを保持するために index を使用できます\n",
    "    # concatはmergeよりも少ないメモリを使用するため、整列は適切です。\n",
    "    df2 = pd.read_pickle(MEAN_ENC)[mean_features] # 「M5 - Custom features」を参照\n",
    "    df2 = df2[df2.index.isin(df.index)]\n",
    "    \n",
    "    df3 = pd.read_pickle(LAGS).iloc[:,3:] # 「M5 - Custom features」を参照\n",
    "    df3 = df3[df3.index.isin(df.index)]\n",
    "    \n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    del df2 # メモリ制限に達しないように削除\n",
    "    \n",
    "    df = pd.concat([df, df3], axis=1)\n",
    "    del df3 # メモリ制限に達しないように削除\n",
    "    \n",
    "    # 特徴量リストを作成する\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # 最初のn行をスキップ\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# トレーニング後にテストを再結合\n",
    "def get_base_test():\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n",
    "\n",
    "\n",
    "########################### 動的移動LAGを作成するヘルパー\n",
    "#################################################################################\n",
    "def make_lag(LAG_DAY):\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'sales_lag_'+str(LAG_DAY)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "def make_lag_roll(LAG_DAY):\n",
    "    shift_day = LAG_DAY[0]\n",
    "    roll_wind = LAG_DAY[1]\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "    return lag_df[[col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### モデルパラメータ\n",
    "#################################################################################\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " モデルのパラメータを詳しく見てみましょう\n",
    "\n",
    "*  'boosting_type': 'gbdt'\n",
    " \n",
    " より高速なトレーニングのための'goss'オプションがあります \n",
    " しかし、通常はアンダーフィットにつながります。 \n",
    " また、良い'dart'モードもあります \n",
    " しかし、トレーニングは永遠にかかります \n",
    " モデルのパフォーマンスは、たくさんのランダムな要素に依存します。\n",
    " https://www.kaggle.com/c/home-credit-default-risk/discussion/60921\n",
    "\n",
    "*  'objective': 'tweedie'\n",
    " Tweedie Gradient Boosting\n",
    " Tweedie 分布はゼロに大量の点を持つ絶対連続な確率分布で\n",
    " 各イベント X が ガンマ分布に従い、イベントの起こる回数 N が\n",
    " ポアソン分布に従う確率過程 （複合ポアソン過程）として表される。\n",
    " https://arxiv.org/pdf/1811.10192.pdf\n",
    "\n",
    " （私にとっては）奇妙ですが、Tweedieは結果に近いです \n",
    " 私自身の醜い損失に。 \n",
    " 私のアドバイスは独自の損失関数を作成することです。\n",
    " https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/140564\n",
    " https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n",
    " poissonカーネルが登場した後、独自の損失関数\n",
    " （Kagglerはパラメータのテストとチューニングに非常に優れています）をすでに使用していると思います。 \n",
    " Tweedieが機能する理由を理解してみてください。 \n",
    " おそらく、新特徴量のオプションまたはデータ変換（ターゲット変換？）が表示されます。\n",
    " 'tweedie_variance_power': 1.1\n",
    " default = 1.5\n",
    " ガンマ分布にシフトするには、これを2に近く設定します\n",
    " ポアソン分布にシフトするには、これを1に近づけます\n",
    " 私のCVは1.1が最適であることを示しています\n",
    " しかし、あなたはあなた自身の選択をすることができます\n",
    "\n",
    "*  'metric': 'rmse'\n",
    "\n",
    " コンペの指標が違うため、何も意味しません。\n",
    " ここでは早期停止を使用しません。\n",
    " したがって、rmseは一般的なモデルのパフォーマンスの概要のみを提供します。\n",
    " また、「偽の」検証セットを使用します。\n",
    " （トレーニングセットの一部となり、一般的なrmseスコアでも意味がないため）\n",
    " https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n",
    "\n",
    "*  'subsample': 0.5\n",
    "\n",
    " オーバーフィットと戦うために役立ちます\n",
    " これはリサンプリングせずにデータの一部をランダムに選択します\n",
    " CVによって選択（私のCVは間違っている可能性があります！\n",
    " 次のカーネルはCVについてです\n",
    "\n",
    "* 'subsample_freq': 1\n",
    "\n",
    " バギングの頻度 \n",
    " デフォルト値-良さそう\n",
    "\n",
    "* 'learning_rate': 0.03\n",
    "\n",
    " CVが選択\n",
    " 小さい-より長いトレーニング\n",
    " しかし、「極小値」で停止するオプションがあります\n",
    " 大きい-より速いトレーニング\n",
    " しかし、「最小値」が見つかりません\n",
    "\n",
    "* 'num_leaves': 2**11-1\n",
    "* 'min_data_in_leaf': 2**12-1\n",
    "\n",
    " より多くの特徴量を使用するようにモデルを強制する\n",
    " 「再帰的」エラーの影響を減らすために必要です\n",
    " また、オーバーフィットにつながります\n",
    " だから小さめに \n",
    " 'max_bin': 100\n",
    "\n",
    "* l1, l2 正則化\n",
    "\n",
    " https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    " 小さな良い説明\n",
    " l2はより大きなnum_leavesで動作します \n",
    " しかし、私のCVはブーストを表示しません\n",
    "                    \n",
    "* 'n_estimators': 1400\n",
    "\n",
    " CVは、州/店舗ごとに異なる値が必要であることを示しています。\n",
    " 現在の値は、一般的な目的で選択されています。\n",
    " パブリックLBに適合しないように注意して早期停止を使用しないためです。\n",
    "\n",
    "* 'feature_fraction': 0.5\n",
    "\n",
    " LightGBMは、各反復（決定木）で特徴量の一部をランダムに選択します。 \n",
    " とてもたくさんの特徴量があります。\n",
    " その多くは「重複」であり、多くは単なる「ノイズ」です\n",
    " CVによる良い値 - 0.5-0.7\n",
    "\n",
    "* 'boost_from_average': False\n",
    "\n",
    " boost_from_averageにカスタム損失「True」はトレーニングをより速くしますが、\n",
    " いくつかの「問題」があります。\n",
    " 私たちのケースではありませんが、短所に注意して使用してください\n",
    " https://github.com/microsoft/LightGBM/issues/1514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 変数\n",
    "#################################################################################\n",
    "VER = 1                          # バージョン\n",
    "SEED = 42                        # \n",
    "seed_everything(SEED)            # 私たちはすべてのものが出来るだけ\n",
    "lgb_params['seed'] = SEED        # 確定的であることを望みます。\n",
    "# N_CORES = psutil.cpu_count() \n",
    "N_CORES = 8# 使用可能なCPUコア\n",
    "\n",
    "\n",
    "#限界と定数\n",
    "TARGET      = 'sales'            # ターゲット\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1913               # trainの終了日\n",
    "P_HORIZON   = 28                 # 予測期間\n",
    "USE_AUX     = True               # 事前学習済みモデルを使用するかどうか\n",
    "\n",
    "#削除する特徴量\n",
    "## これらの機能はオーバーフィットにつながります \n",
    "## または test に存在しない値\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET]\n",
    "mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                   'enc_dept_id_mean','enc_dept_id_std',\n",
    "                   'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "#特徴量のパス\n",
    "ORIGINAL = '../input/m5-forecasting-accuracy/'\n",
    "BASE     = '../input/m5-simple-fe/grid_part_1.pkl'\n",
    "PRICE    = '../input/m5-simple-fe/grid_part_2.pkl'\n",
    "CALENDAR = '../input/m5-simple-fe/grid_part_3.pkl'\n",
    "LAGS     = '../input/m5-lags-features/lags_df_28.pkl'\n",
    "MEAN_ENC = '../input/m5-custom-features/mean_encoding_df.pkl'\n",
    "\n",
    "\n",
    "# AUX（事前学習済み）モデルのパス\n",
    "AUX_MODELS = '../input/m5-aux-models/'\n",
    "\n",
    "\n",
    "#STORES id\n",
    "STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "\n",
    "\n",
    "#LAG作成用の分割\n",
    "SHIFT_DAY  = 28\n",
    "N_LAGS     = 15\n",
    "LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
    "ROLS_SPLIT = []\n",
    "for i in [1,7,14]:\n",
    "    for j in [7,14,30,60]:\n",
    "        ROLS_SPLIT.append([i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 結果を得るために何時間も待ちたくない場合は、各ストアを個別のカーネルでトレーニングしてから、結果に参加します。\n",
    "* 事前トレーニング済みモデルを使用する場合は、トレーニングをスキップできます（この場合、ダミートレーニングを実行して、メモリに問題がなく、この（すべてのカーネル）コードを安全に使用できることを示します）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### AUXモデル\n",
    "\n",
    "if USE_AUX:\n",
    "    lgb_params['n_estimators'] = 2\n",
    "    \n",
    "# ここに比較できるいくつかの「ログ」があります\n",
    "#Train CA_1\n",
    "#[100]\tvalid_0's rmse: 2.02289\n",
    "#[200]\tvalid_0's rmse: 2.0017\n",
    "#[300]\tvalid_0's rmse: 1.99239\n",
    "#[400]\tvalid_0's rmse: 1.98471\n",
    "#[500]\tvalid_0's rmse: 1.97923\n",
    "#[600]\tvalid_0's rmse: 1.97284\n",
    "#[700]\tvalid_0's rmse: 1.96763\n",
    "#[800]\tvalid_0's rmse: 1.9624\n",
    "#[900]\tvalid_0's rmse: 1.95673\n",
    "#[1000]\tvalid_0's rmse: 1.95201\n",
    "#[1100]\tvalid_0's rmse: 1.9476\n",
    "#[1200]\tvalid_0's rmse: 1.9434\n",
    "#[1300]\tvalid_0's rmse: 1.9392\n",
    "#[1400]\tvalid_0's rmse: 1.93446\n",
    "\n",
    "#Train CA_2\n",
    "#[100]\tvalid_0's rmse: 1.88949\n",
    "#[200]\tvalid_0's rmse: 1.84767\n",
    "#[300]\tvalid_0's rmse: 1.83653\n",
    "#[400]\tvalid_0's rmse: 1.82909\n",
    "#[500]\tvalid_0's rmse: 1.82265\n",
    "#[600]\tvalid_0's rmse: 1.81725\n",
    "#[700]\tvalid_0's rmse: 1.81252\n",
    "#[800]\tvalid_0's rmse: 1.80736\n",
    "#[900]\tvalid_0's rmse: 1.80242\n",
    "#[1000]\tvalid_0's rmse: 1.79821\n",
    "#[1100]\tvalid_0's rmse: 1.794\n",
    "#[1200]\tvalid_0's rmse: 1.78973\n",
    "#[1300]\tvalid_0's rmse: 1.78552\n",
    "#[1400]\tvalid_0's rmse: 1.78158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "Train CA_2\n",
      "Train CA_3\n",
      "Train CA_4\n",
      "Train TX_1\n",
      "Train TX_2\n",
      "Train TX_3\n",
      "Train WI_1\n",
      "Train WI_2\n",
      "Train WI_3\n"
     ]
    }
   ],
   "source": [
    "########################### モデルのトレーニング\n",
    "#################################################################################\n",
    "for store_id in STORES_IDS:\n",
    "    print('Train', store_id)\n",
    "    \n",
    "    # 現在の店舗のグリッドを取得\n",
    "    grid_df, features_columns = get_data_by_store(store_id)\n",
    "    \n",
    "    # マスク\n",
    "    # Train （1913未満のすべてのデータ）\n",
    "    # \"Validation\" （過去28日間-実際の検証セットではない\n",
    "    # Test （1913日を超えるすべてのデータ、再帰的機能のギャップあり）\n",
    "    train_mask = grid_df['d']<=END_TRAIN\n",
    "    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "    preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # マスクを適用してlgbデータセットをbinとして保存し、\n",
    "    # dtype変換中のメモリスパイクを削減する\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # 変換を回避するには、常にnp.float32を使用するか、\n",
    "    # トレーニングを開始する前に bin に保存する必要があります\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                       label=grid_df[train_mask][TARGET])\n",
    "    train_data.save_binary('train_data.bin')\n",
    "    train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                       label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # 後の予測のためにデータセットの一部を保存する\n",
    "    # 再帰的に計算する必要がある機能を削除する\n",
    "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "    grid_df = grid_df[keep_cols]\n",
    "    grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "    del grid_df\n",
    "    \n",
    "    # シーダーを再度起動して、\n",
    "    # 各「コード行」np.randomが「進化」するlgbトレーニングを100％確定的にするため、\n",
    "    # 「リセット」する必要がある場合があります。\n",
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          valid_sets = [valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          )\n",
    "    \n",
    "    # モデルを保存-実際の「.bin」ではなく\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # pickleファイルとすると最良の反復（または保存反復）でのみ予測できます\n",
    "    # pickle.dumpは柔軟性を提供します。\n",
    "    # estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - 予測したい反復回数\n",
    "    # NULLまたは<= 0は最適な反復を使用することを意味します\n",
    "    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "    pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # 一時ファイルとオブジェクトを削除して、\n",
    "    # HDDスペースとRAMメモリを解放します\n",
    "    !rm train_data.bin\n",
    "    del train_data, valid_data, estimator\n",
    "    gc.collect()\n",
    "    \n",
    "    # 予測のためのモデル特徴量の保持\n",
    "    MODEL_FEATURES = features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  3.04 min round |  3.04 min total |  37325.53 day sales |\n",
      "Predict | Day: 2\n",
      "##########  3.01 min round |  6.05 min total |  35278.08 day sales |\n",
      "Predict | Day: 3\n",
      "##########  3.14 min round |  9.19 min total |  34734.42 day sales |\n",
      "Predict | Day: 4\n",
      "##########  3.20 min round |  12.39 min total |  35304.90 day sales |\n",
      "Predict | Day: 5\n",
      "##########  3.04 min round |  15.43 min total |  41689.88 day sales |\n",
      "Predict | Day: 6\n",
      "##########  3.33 min round |  18.77 min total |  50885.83 day sales |\n",
      "Predict | Day: 7\n",
      "##########  3.03 min round |  21.80 min total |  53387.48 day sales |\n",
      "Predict | Day: 8\n",
      "##########  3.07 min round |  24.87 min total |  44011.68 day sales |\n",
      "Predict | Day: 9\n",
      "##########  3.18 min round |  28.05 min total |  44332.58 day sales |\n",
      "Predict | Day: 10\n",
      "##########  3.08 min round |  31.13 min total |  38824.09 day sales |\n",
      "Predict | Day: 11\n",
      "##########  3.04 min round |  34.17 min total |  40793.79 day sales |\n",
      "Predict | Day: 12\n",
      "##########  3.08 min round |  37.25 min total |  45888.34 day sales |\n",
      "Predict | Day: 13\n",
      "##########  3.08 min round |  40.32 min total |  53800.37 day sales |\n",
      "Predict | Day: 14\n",
      "##########  3.09 min round |  43.41 min total |  46261.08 day sales |\n",
      "Predict | Day: 15\n",
      "##########  3.10 min round |  46.51 min total |  44790.64 day sales |\n",
      "Predict | Day: 16\n",
      "##########  3.21 min round |  49.72 min total |  39376.42 day sales |\n",
      "Predict | Day: 17\n",
      "##########  3.11 min round |  52.83 min total |  40344.46 day sales |\n",
      "Predict | Day: 18\n",
      "##########  3.13 min round |  55.96 min total |  40908.18 day sales |\n",
      "Predict | Day: 19\n",
      "##########  3.28 min round |  59.24 min total |  43885.84 day sales |\n",
      "Predict | Day: 20\n",
      "##########  3.07 min round |  62.31 min total |  53607.75 day sales |\n",
      "Predict | Day: 21\n",
      "##########  3.08 min round |  65.39 min total |  55923.97 day sales |\n",
      "Predict | Day: 22\n",
      "##########  3.08 min round |  68.48 min total |  41769.62 day sales |\n",
      "Predict | Day: 23\n",
      "##########  3.08 min round |  71.55 min total |  37885.52 day sales |\n",
      "Predict | Day: 24\n",
      "##########  3.09 min round |  74.64 min total |  37069.51 day sales |\n",
      "Predict | Day: 25\n",
      "##########  3.09 min round |  77.73 min total |  36906.47 day sales |\n",
      "Predict | Day: 26\n",
      "##########  3.08 min round |  80.81 min total |  41743.24 day sales |\n",
      "Predict | Day: 27\n",
      "##########  3.10 min round |  83.91 min total |  50640.16 day sales |\n",
      "Predict | Day: 28\n",
      "##########  3.09 min round |  87.00 min total |  51429.39 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.754956</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.723041</td>\n",
       "      <td>0.757371</td>\n",
       "      <td>0.930978</td>\n",
       "      <td>1.017402</td>\n",
       "      <td>1.149758</td>\n",
       "      <td>0.850865</td>\n",
       "      <td>0.856534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770908</td>\n",
       "      <td>0.943370</td>\n",
       "      <td>0.963763</td>\n",
       "      <td>0.812957</td>\n",
       "      <td>0.757883</td>\n",
       "      <td>0.723716</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>0.877107</td>\n",
       "      <td>1.034379</td>\n",
       "      <td>0.944918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.191938</td>\n",
       "      <td>0.187140</td>\n",
       "      <td>0.182817</td>\n",
       "      <td>0.181085</td>\n",
       "      <td>0.222433</td>\n",
       "      <td>0.264552</td>\n",
       "      <td>0.295977</td>\n",
       "      <td>0.237515</td>\n",
       "      <td>0.222527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207496</td>\n",
       "      <td>0.222726</td>\n",
       "      <td>0.225074</td>\n",
       "      <td>0.194898</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>0.185044</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.232550</td>\n",
       "      <td>0.247974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.445837</td>\n",
       "      <td>0.421734</td>\n",
       "      <td>0.418613</td>\n",
       "      <td>0.417528</td>\n",
       "      <td>0.580683</td>\n",
       "      <td>0.742513</td>\n",
       "      <td>0.761937</td>\n",
       "      <td>0.493187</td>\n",
       "      <td>0.496076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549582</td>\n",
       "      <td>0.700338</td>\n",
       "      <td>0.704256</td>\n",
       "      <td>0.445749</td>\n",
       "      <td>0.417246</td>\n",
       "      <td>0.445126</td>\n",
       "      <td>0.476210</td>\n",
       "      <td>0.608853</td>\n",
       "      <td>0.724363</td>\n",
       "      <td>0.684994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.622182</td>\n",
       "      <td>1.276876</td>\n",
       "      <td>1.333453</td>\n",
       "      <td>1.523020</td>\n",
       "      <td>1.917593</td>\n",
       "      <td>2.878792</td>\n",
       "      <td>3.189502</td>\n",
       "      <td>1.768638</td>\n",
       "      <td>1.480806</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861259</td>\n",
       "      <td>2.673030</td>\n",
       "      <td>3.245865</td>\n",
       "      <td>1.695736</td>\n",
       "      <td>1.450723</td>\n",
       "      <td>1.448565</td>\n",
       "      <td>1.424861</td>\n",
       "      <td>2.055415</td>\n",
       "      <td>3.144716</td>\n",
       "      <td>3.403936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>0.943043</td>\n",
       "      <td>0.853174</td>\n",
       "      <td>0.860399</td>\n",
       "      <td>0.940414</td>\n",
       "      <td>1.067462</td>\n",
       "      <td>1.469891</td>\n",
       "      <td>1.518171</td>\n",
       "      <td>0.978536</td>\n",
       "      <td>0.969054</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039325</td>\n",
       "      <td>1.597230</td>\n",
       "      <td>1.598630</td>\n",
       "      <td>1.072630</td>\n",
       "      <td>0.863821</td>\n",
       "      <td>0.962907</td>\n",
       "      <td>0.931099</td>\n",
       "      <td>1.103105</td>\n",
       "      <td>1.573273</td>\n",
       "      <td>1.517332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.341034</td>\n",
       "      <td>0.306024</td>\n",
       "      <td>0.305877</td>\n",
       "      <td>0.291247</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>0.439060</td>\n",
       "      <td>0.446426</td>\n",
       "      <td>0.415796</td>\n",
       "      <td>0.495530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464148</td>\n",
       "      <td>0.502765</td>\n",
       "      <td>0.563858</td>\n",
       "      <td>0.436067</td>\n",
       "      <td>0.378407</td>\n",
       "      <td>0.361966</td>\n",
       "      <td>0.356825</td>\n",
       "      <td>0.376087</td>\n",
       "      <td>0.408023</td>\n",
       "      <td>0.475888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.265576</td>\n",
       "      <td>0.220269</td>\n",
       "      <td>0.183326</td>\n",
       "      <td>0.205311</td>\n",
       "      <td>0.247020</td>\n",
       "      <td>0.320821</td>\n",
       "      <td>0.316065</td>\n",
       "      <td>0.354473</td>\n",
       "      <td>0.364930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264059</td>\n",
       "      <td>0.410711</td>\n",
       "      <td>0.468152</td>\n",
       "      <td>0.283857</td>\n",
       "      <td>0.231140</td>\n",
       "      <td>0.213263</td>\n",
       "      <td>0.189287</td>\n",
       "      <td>0.194434</td>\n",
       "      <td>0.262053</td>\n",
       "      <td>0.265324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.622677</td>\n",
       "      <td>0.521962</td>\n",
       "      <td>0.471177</td>\n",
       "      <td>0.488638</td>\n",
       "      <td>0.628324</td>\n",
       "      <td>0.775578</td>\n",
       "      <td>0.947372</td>\n",
       "      <td>1.078246</td>\n",
       "      <td>1.173103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919912</td>\n",
       "      <td>1.304917</td>\n",
       "      <td>1.520844</td>\n",
       "      <td>0.995182</td>\n",
       "      <td>0.659822</td>\n",
       "      <td>0.631202</td>\n",
       "      <td>0.598296</td>\n",
       "      <td>0.660605</td>\n",
       "      <td>0.791624</td>\n",
       "      <td>0.841313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.908515</td>\n",
       "      <td>0.758296</td>\n",
       "      <td>0.803343</td>\n",
       "      <td>0.883420</td>\n",
       "      <td>1.219577</td>\n",
       "      <td>1.148522</td>\n",
       "      <td>1.193198</td>\n",
       "      <td>1.250385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966542</td>\n",
       "      <td>1.224828</td>\n",
       "      <td>1.349287</td>\n",
       "      <td>0.951517</td>\n",
       "      <td>0.908335</td>\n",
       "      <td>0.859575</td>\n",
       "      <td>0.794154</td>\n",
       "      <td>0.947509</td>\n",
       "      <td>1.057468</td>\n",
       "      <td>1.175530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.195621</td>\n",
       "      <td>1.128930</td>\n",
       "      <td>1.155793</td>\n",
       "      <td>1.653968</td>\n",
       "      <td>2.071246</td>\n",
       "      <td>2.574962</td>\n",
       "      <td>2.484251</td>\n",
       "      <td>2.008058</td>\n",
       "      <td>2.116987</td>\n",
       "      <td>...</td>\n",
       "      <td>1.784271</td>\n",
       "      <td>2.158012</td>\n",
       "      <td>2.144815</td>\n",
       "      <td>1.540104</td>\n",
       "      <td>1.555882</td>\n",
       "      <td>1.484060</td>\n",
       "      <td>1.424996</td>\n",
       "      <td>1.617288</td>\n",
       "      <td>1.969922</td>\n",
       "      <td>1.915427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  0.754956  0.710293  0.723041  0.757371   \n",
       "1      HOBBIES_1_002_CA_1_validation  0.191938  0.187140  0.182817  0.181085   \n",
       "2      HOBBIES_1_003_CA_1_validation  0.445837  0.421734  0.418613  0.417528   \n",
       "3      HOBBIES_1_004_CA_1_validation  1.622182  1.276876  1.333453  1.523020   \n",
       "4      HOBBIES_1_005_CA_1_validation  0.943043  0.853174  0.860399  0.940414   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_validation  0.341034  0.306024  0.305877  0.291247   \n",
       "30486    FOODS_3_824_WI_3_validation  0.265576  0.220269  0.183326  0.205311   \n",
       "30487    FOODS_3_825_WI_3_validation  0.622677  0.521962  0.471177  0.488638   \n",
       "30488    FOODS_3_826_WI_3_validation  0.998571  0.908515  0.758296  0.803343   \n",
       "30489    FOODS_3_827_WI_3_validation  0.195621  1.128930  1.155793  1.653968   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      0.930978  1.017402  1.149758  0.850865  0.856534  ...  0.770908   \n",
       "1      0.222433  0.264552  0.295977  0.237515  0.222527  ...  0.207496   \n",
       "2      0.580683  0.742513  0.761937  0.493187  0.496076  ...  0.549582   \n",
       "3      1.917593  2.878792  3.189502  1.768638  1.480806  ...  1.861259   \n",
       "4      1.067462  1.469891  1.518171  0.978536  0.969054  ...  1.039325   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.352295  0.439060  0.446426  0.415796  0.495530  ...  0.464148   \n",
       "30486  0.247020  0.320821  0.316065  0.354473  0.364930  ...  0.264059   \n",
       "30487  0.628324  0.775578  0.947372  1.078246  1.173103  ...  0.919912   \n",
       "30488  0.883420  1.219577  1.148522  1.193198  1.250385  ...  0.966542   \n",
       "30489  2.071246  2.574962  2.484251  2.008058  2.116987  ...  1.784271   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      0.943370  0.963763  0.812957  0.757883  0.723716  0.773000  0.877107   \n",
       "1      0.222726  0.225074  0.194898  0.177903  0.185044  0.178583  0.192817   \n",
       "2      0.700338  0.704256  0.445749  0.417246  0.445126  0.476210  0.608853   \n",
       "3      2.673030  3.245865  1.695736  1.450723  1.448565  1.424861  2.055415   \n",
       "4      1.597230  1.598630  1.072630  0.863821  0.962907  0.931099  1.103105   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  0.502765  0.563858  0.436067  0.378407  0.361966  0.356825  0.376087   \n",
       "30486  0.410711  0.468152  0.283857  0.231140  0.213263  0.189287  0.194434   \n",
       "30487  1.304917  1.520844  0.995182  0.659822  0.631202  0.598296  0.660605   \n",
       "30488  1.224828  1.349287  0.951517  0.908335  0.859575  0.794154  0.947509   \n",
       "30489  2.158012  2.144815  1.540104  1.555882  1.484060  1.424996  1.617288   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.034379  0.944918  \n",
       "1      0.232550  0.247974  \n",
       "2      0.724363  0.684994  \n",
       "3      3.144716  3.403936  \n",
       "4      1.573273  1.517332  \n",
       "...         ...       ...  \n",
       "30485  0.408023  0.475888  \n",
       "30486  0.262053  0.265324  \n",
       "30487  0.791624  0.841313  \n",
       "30488  1.057468  1.175530  \n",
       "30489  1.969922  1.915427  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### 予測\n",
    "#################################################################################\n",
    "\n",
    "# 予測を保存するためのダミーデータフレームを作成する\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# テストデータセットをトレーニングデータの一部に結合して、\n",
    "# 再帰的な特徴量を作成します\n",
    "base_test = get_base_test()\n",
    "\n",
    "# 予測時間を測定するタイマー\n",
    "main_time = time.time()\n",
    "\n",
    "# 各予測日にループする移動LAGは最も時間がかかるため、\n",
    "# 1日全体で計算します。\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 移動LAGを計算するための一時的なグリッドを作成する\n",
    "    grid_df = base_test.copy()\n",
    "    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "        \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # すべてのモデルを読んで、日/店舗のペアごとに予測を行う\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        if USE_AUX:\n",
    "            model_path = AUX_MODELS + model_path\n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # 適切な列の名前を付け、all_preds に追加します\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### 書き出す\n",
    "#################################################################################\n",
    "# コンぺのサンプル提出を読んで、予測を結合する\n",
    "# 「_validation」データのみの予測があるため\n",
    "# 「_evaluation」アイテムに対してfillna（）を実行する必要がある\n",
    "submission = pd.read_csv(ORIGINAL+'sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##以下は翻訳しません。ご自身でご判断ください。\n",
    "\n",
    "# Summary\n",
    "\n",
    "# Of course here is no magic at all.\n",
    "# No \"Novel\" features and no brilliant ideas.\n",
    "# We just carefully joined all\n",
    "# our previous fe work and created a model.\n",
    "\n",
    "# Also!\n",
    "# In my opinion this strategy is a \"dead end\".\n",
    "# Overfits a lot LB and with 1 final submission \n",
    "# you have no option to risk.\n",
    "\n",
    "\n",
    "# Improvement should come from:\n",
    "# Loss function\n",
    "# Data representation\n",
    "# Stable CV\n",
    "# Good features reduction strategy\n",
    "# Predictions stabilization with NN\n",
    "# Trend prediction\n",
    "# Real zero sales detection/classification\n",
    "\n",
    "\n",
    "# Good kernels references \n",
    "## (the order is random and the list is not complete):\n",
    "# https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv\n",
    "# https://www.kaggle.com/jpmiller/grouping-items-by-stockout-pattern\n",
    "# https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda\n",
    "# https://www.kaggle.com/sibmike/m5-out-of-stock-feature\n",
    "# https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table\n",
    "# https://www.kaggle.com/yassinealouini/seq2seq\n",
    "# https://www.kaggle.com/kailex/m5-forecaster-v2\n",
    "# https://www.kaggle.com/aerdem4/m5-lofo-importance-on-gpu-via-rapids-xgboost\n",
    "\n",
    "\n",
    "# Features were created in these kernels:\n",
    "## \n",
    "# Mean encodings and PCA options\n",
    "# https://www.kaggle.com/kyakovlev/m5-custom-features\n",
    "##\n",
    "# Lags and rolling lags\n",
    "# https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "##\n",
    "# Base Grid and base features (calendar/price/etc)\n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "\n",
    "\n",
    "# Personal request\n",
    "# Please don't upvote any ensemble and copypaste kernels\n",
    "## The worst case is ensemble without any analyse.\n",
    "## The best choice - just ignore it.\n",
    "## I would like to see more kernels with interesting and original approaches.\n",
    "## Don't feed copypasters with upvotes.\n",
    "\n",
    "## It doesn't mean that you should not fork and improve others kernels\n",
    "## but I would like to see params and code tuning based on some CV and analyse\n",
    "## and not only on LB probing.\n",
    "## Small changes could be shared in comments and authors can improve their kernel.\n",
    "\n",
    "## Feel free to criticize this kernel as my knowlege is very limited\n",
    "## and I can be wrong in code and descriptions. \n",
    "## Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
